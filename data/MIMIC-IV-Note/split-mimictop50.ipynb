{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "with open('/home/weisi/Temporal/data/MIMIC-IV-Note/mimic-top50.json', 'r', encoding='utf-8') as f:\n",
    "    df=pd.read_json(f,lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.groupby('time').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "seed=2\n",
    "\n",
    "folder_path ='/home/weisi/Temporal/data/MIMIC-IV-Note/seed{}/'.format(seed)\n",
    "\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "# devide dataset to 3 time periods\n",
    "df_2008_2010 = df[df['time'] == '2008 - 2010']\n",
    "df_2011_2013 = df[df['time'] == '2011 - 2013']\n",
    "df_2014_2016 = df[df['time'] == '2014 - 2016']\n",
    "df_2017_2019 = df[df['time'] == '2017 - 2019']\n",
    "\n",
    "# reduce the datasets to the same size\n",
    "min_size = min(len(df_2008_2010), len(df_2011_2013), len(df_2014_2016), len(df_2017_2019))\n",
    "\n",
    "\n",
    "df_2008_2010_sampled = df_2008_2010.sample(n=min_size, random_state=seed)\n",
    "df_2011_2013_sampled = df_2011_2013.sample(n=min_size, random_state=seed)\n",
    "df_2014_2016_sampled = df_2014_2016.sample(n=min_size, random_state=seed)\n",
    "df_2017_2019_sampled = df_2017_2019.sample(n=min_size, random_state=seed)\n",
    "\n",
    "\n",
    "def save_datasets(df, period,seed):\n",
    "    # split train, validation and test datasets by ratio 0.7 0.15 0.15\n",
    "    train, test = train_test_split(df, test_size=0.3, random_state=seed)  \n",
    "    validation, test = train_test_split(test, test_size=0.5, random_state=seed)  \n",
    "\n",
    "    # save files\n",
    "    train_filename = f'mimic_{period}_train.json'\n",
    "    validation_filename = f'mimic_{period}_validation.json'\n",
    "    test_filename = f'mimic_{period}_test.json'\n",
    "    train.to_json(os.path.join(folder_path, train_filename), orient='records', lines=True)\n",
    "    validation.to_json(os.path.join(folder_path, validation_filename), orient='records', lines=True)\n",
    "    test.to_json(os.path.join(folder_path, test_filename), orient='records', lines=True)\n",
    "\n",
    "\n",
    "save_datasets(df_2008_2010_sampled, 'T1_2008-2010',seed)\n",
    "save_datasets(df_2011_2013_sampled, 'T2_2011-2013',seed)\n",
    "save_datasets(df_2014_2016_sampled, 'T3_2014-2016',seed)\n",
    "save_datasets(df_2017_2019_sampled, 'T4_2017-2019',seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_period = min_size // 4  # floor\n",
    "\n",
    "# create a all year data that draw equal data from 4 time periods and has same size as other time periods\n",
    "allyear_sampled = pd.concat([\n",
    "    df_2008_2010.sample(n=samples_per_period, random_state=1),\n",
    "    df_2011_2013.sample(n=samples_per_period, random_state=1),\n",
    "    df_2014_2016.sample(n=samples_per_period, random_state=1),\n",
    "    df_2017_2019.sample(n=samples_per_period, random_state=1)\n",
    "])\n",
    "# randomlize the order od all year data\n",
    "allyear_sampled = allyear_sampled.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "save_datasets(allyear_sampled, 'Allyear_sampled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = allyear_sampled.sample(n=1000, random_state=1)\n",
    "save_datasets(df_test, 'test_sample_1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "df_08_10 = df[df['time'] == '2008 - 2010'].sample(n=35000)\n",
    "tqdm.pandas()#sets up the tqdm progress bar for tracking the progress of the following operation\n",
    "\n",
    "df_08_10.to_json('mimic-top50_2008-2010_sample35k.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_17_19 = df[df['time'] == '2017 - 2019'].sample(n=4000)\n",
    "tqdm.pandas()#sets up the tqdm progress bar for tracking the progress of the following operation\n",
    "\n",
    "df_17_19.to_json('mimic-top50_2017-2019_sample4k.json', orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

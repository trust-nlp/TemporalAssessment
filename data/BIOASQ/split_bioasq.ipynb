{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "alldf = pd.read_json('/home/weisi/TemporalAssessment/data/BIOASQ/BioASQ.json', lines=True)\n",
    "\n",
    "# split the factoid questions data\n",
    "df=alldf[alldf['type']=='factoid']\n",
    "df_2013_2015 = df[df['year'].isin([2013, 2015])]\n",
    "df_2016_2018 = df[df['year'].isin([2016, 2018])]\n",
    "df_2019_2020 = df[df['year'].isin([2019, 2020])]\n",
    "df_2021_2022 = df[df['year'].isin([2021, 2022])]\n",
    "df_all_year= df[df['year'].isin([2013, 2020])]\n",
    "\n",
    "min_size = min(len(df_2013_2015), len(df_2016_2018),len(df_2019_2020), len(df_2021_2022))\n",
    "\n",
    "def split_and_save_datasets(df,period,seed,folder_path):\n",
    "    # split train, validation and test datasets by ratio 0.6 0.2 0.2\n",
    "    train, rest = train_test_split(df, test_size=0.4, random_state=seed)  \n",
    "    validation, test = train_test_split(rest, test_size=0.5, random_state=seed)  \n",
    "    # save files\n",
    "    train_filename = f'{period}_train.json'\n",
    "    validation_filename = f'{period}_validation.json'\n",
    "    test_filename = f'{period}_test.json'\n",
    "    train.to_json(os.path.join(folder_path, train_filename), orient='records', lines=True)\n",
    "    validation.to_json(os.path.join(folder_path, validation_filename), orient='records', lines=True)\n",
    "    test.to_json(os.path.join(folder_path, test_filename), orient='records', lines=True)\n",
    "\n",
    "for seed in range(1, 2):  # randomly split 5 times\n",
    "    folder_path ='/home/weisi/TemporalAssessment/data/BIOASQ/seed{}/'.format(seed)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    df_2013_2015_sampled = df_2013_2015.sample(n=min_size, random_state=seed)\n",
    "    df_2016_2018_sampled = df_2016_2018.sample(n=min_size, random_state=seed)\n",
    "    df_2019_2020_sampled = df_2019_2020.sample(n=min_size, random_state=seed)\n",
    "    df_2021_2022_sampled = df_2021_2022.sample(n=min_size, random_state=seed)\n",
    "    all_year_sampled = df_all_year.sample(n=min_size, random_state=seed)\n",
    "    split_and_save_datasets(df_2013_2015_sampled, 'bioasq_factoid_T1_2013-2015',seed,folder_path)\n",
    "    split_and_save_datasets(df_2016_2018_sampled, 'bioasq_factoid_T2_2016-2018',seed,folder_path)\n",
    "    split_and_save_datasets(df_2019_2020_sampled, 'bioasq_factoid_T3_2019-2020',seed,folder_path)\n",
    "    split_and_save_datasets(df_2021_2022_sampled, 'bioasq_factoid_T4_2021-2022',seed,folder_path)\n",
    "    split_and_save_datasets(all_year_sampled, 'bioasq_factoid_AY_2013-2020',seed,folder_path)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

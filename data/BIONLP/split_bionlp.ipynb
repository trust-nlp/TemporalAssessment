{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year\n",
      "2014      174\n",
      "2015      279\n",
      "2016      324\n",
      "2017     3365\n",
      "2018    23805\n",
      "2019    11094\n",
      "2020      285\n",
      "2021       34\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('/home/weisi/Temporal/data/BIONLP/bionlp.jsonl', lines=True)\n",
    "\n",
    "\n",
    "df['pmid'] = df['id']\n",
    "df['id'] = [format(i, 'x') for i in range(len(df))]\n",
    "df['context'] = df['long']\n",
    "df['answer'] = df.apply(lambda x: {'text': [x['short']]}, axis=1)\n",
    "\n",
    "df = df[['id', 'pmid', 'question', 'context', 'answer', 'year']]\n",
    "\n",
    "year_counts = df.groupby('year').size()\n",
    "print(year_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import os\n",
    "\n",
    "# devide dataset to 3 year periods\n",
    "df_2014_2015 = df[df['year'].isin([2014, 2015])]\n",
    "df_2016_2017 = df[df['year'].isin([2016, 2017])]\n",
    "df_2018_2019 = df[df['year'].isin([2018, 2019])]\n",
    "df_2020_2021 = df[df['year'].isin([2020, 2021])]\n",
    "df_all_year= df[df['year'].isin([2014, 2019])]\n",
    "\n",
    "min_size = min(len(df_2014_2015), len(df_2016_2017),len(df_2018_2019), len(df_2020_2021))\n",
    "\n",
    "def split_and_save_datasets(df,period,seed,folder_path):\n",
    "    # split train, validation and test datasets by ratio 0.6 0.2 0.2\n",
    "    train, rest = train_test_split(df, test_size=0.4, random_state=seed)  \n",
    "    validation, test = train_test_split(rest, test_size=0.5, random_state=seed)  \n",
    "    # save files\n",
    "    train_filename = f'{period}_train.json'\n",
    "    validation_filename = f'{period}_validation.json'\n",
    "    test_filename = f'{period}_test.json'\n",
    "    train.to_json(os.path.join(folder_path, train_filename), orient='records', lines=True)\n",
    "    validation.to_json(os.path.join(folder_path, validation_filename), orient='records', lines=True)\n",
    "    test.to_json(os.path.join(folder_path, test_filename), orient='records', lines=True)\n",
    "\n",
    "\n",
    "for seed in range(1, 6):  # randomly split 5 times\n",
    "    folder_path ='/home/weisi/TemporalAssessment/data/BIONLP/seed{}/'.format(seed)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    df_2014_2015_sampled = df_2014_2015.sample(n=min_size, random_state=seed)\n",
    "    df_2016_2017_sampled = df_2016_2017.sample(n=min_size, random_state=seed)\n",
    "    df_2018_2019_sampled = df_2018_2019.sample(n=min_size, random_state=seed)\n",
    "    df_2020_2021_sampled = df_2020_2021.sample(n=min_size, random_state=seed)\n",
    "    all_year_sampled = df_all_year.sample(n=min_size, random_state=seed)\n",
    "    split_and_save_datasets(df_2014_2015_sampled, 'bionlp_T1_2014-2015',seed,folder_path)\n",
    "    split_and_save_datasets(df_2016_2017_sampled, 'bionlp_T2_2016-2017',seed,folder_path)\n",
    "    split_and_save_datasets(df_2018_2019_sampled, 'bionlp_T3_2018-2019',seed,folder_path)\n",
    "    split_and_save_datasets(df_2020_2021_sampled, 'bionlp_T4_2020-2021',seed,folder_path)\n",
    "    split_and_save_datasets(all_year_sampled, 'bionlp_AY_2014-2021',seed,folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_data(data, filename):\n",
    "    data.to_json(filename, orient='records')\n",
    "\n",
    "\n",
    "def split_and_save_data(df, year):\n",
    "    # select year and random\n",
    "    df_year = df[df['year'] == year].sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # 0.7 0.15 0.15\n",
    "    train_split = int(0.7 * len(df_year))\n",
    "    val_split = int(0.85 * len(df_year))\n",
    "\n",
    "    train_data = df_year.iloc[:train_split]\n",
    "    val_data = df_year.iloc[train_split:val_split]\n",
    "    test_data = df_year.iloc[val_split:]\n",
    "\n",
    "    save_data(train_data, f'bionlp_{year}_train.json')\n",
    "    save_data(val_data, f'bionlp_{year}_val.json')\n",
    "    save_data(test_data, f'bionlp_{year}_test.json')\n",
    "\n",
    "'''for year in df['year'].unique():\n",
    "    split_and_save_data(df, year)'''\n",
    "\n",
    "'''for year in range(2012, 2016):\n",
    "    split_and_save_data(df, year)'''\n",
    "\n",
    "split_and_save_data(df, 2016)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
